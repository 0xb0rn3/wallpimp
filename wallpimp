#!/usr/bin/env python3
"""
WallPimp v2.4 - Enhanced Cross-Platform Automated Wallpaper Collection Tool
Optimized for large repositories with precise file handling and verification.
Features improved duplicate detection, download resumption, and interactive file management.
Developed by ã‚½ãƒ­ãƒƒã‚¯ã‚¹ (oxborn3)
GitHub: https://github.com/0xb0rn3
"""
import os
import sys
import shutil
import subprocess
import platform
import requests
from pathlib import Path
import hashlib
import time
import logging
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Set, Dict, Tuple, Optional
from tqdm import tqdm
import re
from datetime import datetime
import signal
import threading
import tempfile

# Enhanced dependency handling for PIL/Pillow
try:
    from PIL import Image
except ImportError:
    print("Pillow not found. Attempting automatic installation...")
    try:
        subprocess.check_call([sys.executable, "-m", "pip", "install", "--user", "Pillow"])
        from PIL import Image
    except Exception as e:
        print(f"Error installing Pillow: {e}")
        print("\nPlease install Pillow manually:")
        print("pip install Pillow")
        sys.exit(1)

# Configuration constants with improved defaults
WALLPAPER_REPOS = [
    "https://github.com/dharmx/walls",
    "https://github.com/FrenzyExists/wallpapers",
    "https://github.com/Dreamer-Paul/Anime-Wallpaper",
    "https://github.com/michaelScopic/Wallpapers",
    "https://github.com/ryan4yin/wallpapers",
    "https://github.com/HENTAI-CODER/Anime-Wallpaper",
    "https://github.com/port19x/Wallpapers",
    "https://github.com/k1ng440/Wallpapers",
    "https://github.com/vimfn/walls",
    "https://github.com/expandpi/wallpapers"
]

class WallPimp:
    def __init__(self):
        # Initialize DependencyManager first
        DependencyManager.check_environment()
        
        self.output_folder = self._get_default_output_folder()
        # Create output folder and its parent directories
        self.output_folder.mkdir(parents=True, exist_ok=True)
        
        # Create log directory if it doesn't exist
        log_dir = self.output_folder
        log_dir.mkdir(parents=True, exist_ok=True)
        
        self.temp_dir = Path(tempfile.mkdtemp(prefix="wallpimp_"))
        self.state_file = self.output_folder / '.wallpimp_state.json'
        
        # Set up logging before initializing other components
        self._setup_logging()
        
        self.download_state = DownloadState(self.state_file)
        self.processed_hashes = {}
        self.total_wallpapers = 0
        self.successful_repos = 0
        self.failed_downloads = []
        self.stop_event = threading.Event()
        
        # Register signal handlers
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)

    def _setup_logging(self):
        """Configure rotating log handler with improved formatting and directory creation."""
        log_file = self.output_folder / 'wallpimp.log'
        
        # Ensure the parent directory exists
        log_file.parent.mkdir(parents=True, exist_ok=True)
        
        # Configure logging with both file and console output
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger('WallPimp')

    def _cleanup(self):
        """Clean up temporary files and directories."""
        try:
            if self.temp_dir.exists():
                shutil.rmtree(self.temp_dir, ignore_errors=True)
        except Exception as e:
            logging.error(f"Error during cleanup: {e}")

    def _get_default_output_folder(self) -> Path:
        """Get the default output folder with extended platform support."""
        system = platform.system().lower()
        if system == 'windows':
            base_dir = os.environ.get('USERPROFILE')
        elif system == 'darwin':
            base_dir = os.path.expanduser('~/Pictures')
        else:  # Linux and others
            base_dir = os.environ.get('XDG_PICTURES_DIR', 
                                    os.path.expanduser('~/Pictures'))
        
        return Path(base_dir) / 'WallPimp'

    def process_repository(self, repo_url: str) -> Tuple[int, str]:
        """Process repository with enhanced error handling and verification."""
        if repo_url in self.download_state.processed_repos:
            return 0, f"Skipping already processed repository: {repo_url}"

        repo_name = repo_url.split('/')[-1].replace('.git', '')
        repo_path = self.temp_dir / repo_name
        wallpapers_count = 0
        status_message = ""
        
        try:
            if not self._clone_repository(repo_url, repo_path):
                return 0, f"âš ï¸  Failed to clone {repo_name}"

            # Find all potential image files
            image_files = []
            for ext in IMAGE_FORMATS:
                image_files.extend(repo_path.glob(f"**/*{ext}"))
                image_files.extend(repo_path.glob(f"**/*{ext.upper()}"))

            # Process images with detailed progress
            with tqdm(total=len(image_files), 
                     desc=f"Processing {repo_name}", 
                     leave=False) as pbar:
                for image_file in image_files:
                    if self.stop_event.is_set():
                        break

                    try:
                        # Validate and get hash
                        is_valid, file_hash = ImageProcessor.validate_image(image_file)
                        if not is_valid or not file_hash:
                            pbar.update(1)
                            continue

                        # Generate unique filename
                        new_name = self._sanitize_filename(
                            f"{repo_name}_{image_file.name}")
                        destination = self.output_folder / new_name

                        # Handle duplicates
                        if file_hash in self.processed_hashes:
                            pbar.update(1)
                            continue

                        # Copy file with verification
                        shutil.copy2(image_file, destination)
                        
                        # Verify copy integrity
                        if not self._verify_file_integrity(destination, file_hash):
                            self.logger.error(
                                f"Integrity check failed for {destination}")
                            self.failed_downloads.append((str(image_file), 
                                                       destination))
                            if destination.exists():
                                destination.unlink()
                            continue

                        # Update tracking
                        self.processed_hashes[file_hash] = destination
                        self.download_state.downloaded_files.add(str(destination))
                        wallpapers_count += 1
                        
                    except Exception as e:
                        self.logger.error(f"Error processing {image_file}: {str(e)}")
                        self.failed_downloads.append((str(image_file), destination))
                    finally:
                        pbar.update(1)

            self.successful_repos += 1
            self.download_state.processed_repos.add(repo_url)
            status_message = f"âœ“ Downloaded {wallpapers_count} wallpapers from {repo_name}"
            
        except Exception as e:
            self.logger.error(f"Error processing repository {repo_name}: {str(e)}")
            status_message = f"âš ï¸  Error processing {repo_name}: {str(e)}"
        finally:
            # Clean up repository directory
            if repo_path.exists():
                shutil.rmtree(repo_path, ignore_errors=True)
                
        return wallpapers_count, status_message

    def _clone_repository(self, repo_url: str, repo_path: Path) -> bool:
        """Clone repository with improved error handling and progress tracking."""
        for attempt in range(MAX_RETRIES):
            try:
                if attempt > 0:
                    wait_time = min(2 ** attempt, 60)
                    self.logger.info(
                        f"Retry attempt {attempt + 1} for {repo_url}, "
                        f"waiting {wait_time}s")
                    time.sleep(wait_time)

                print(f"\nCloning {repo_url}...")
                
                # Use partial clone for large repositories with depth limit
                cmd = [
                    'git', 'clone',
                    '--filter=blob:limit=1g',  # Filter large files
                    '--depth=1',  # Shallow clone for faster download
                    '--single-branch',
                    '--progress',
                    repo_url,
                    str(repo_path)
                ]
                
                process = subprocess.Popen(
                    cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    universal_newlines=True
                )
                
                # Monitor clone progress with timeout
                start_time = time.time()
                while True:
                    if process.stderr is None:
                        break
                        
                    if time.time() - start_time > CLONE_TIMEOUT:
                        process.terminate()
                        raise subprocess.TimeoutExpired(cmd, CLONE_TIMEOUT)
                        
                    output = process.stderr.readline()
                    if output == '' and process.poll() is not None:
                        break
                    if output:
                        if 'Receiving objects:' in output:
                            print(f"\r{output.strip()}", end='')
                
                if process.wait() == 0:
                    print("\nClone completed successfully")
                    return True
                    
            except subprocess.TimeoutExpired:
                self.logger.error(f"Timeout while cloning {repo_url}")
                if repo_path.exists():
                    shutil.rmtree(repo_path, ignore_errors=True)
            except subprocess.SubprocessError as e:
                self.logger.error(f"Error cloning {repo_url}: {str(e)}")
                if repo_path.exists():
                    shutil.rmtree(repo_path, ignore_errors=True)
            
        return False

    def run(self):
        """Main execution method with improved error handling and resource management."""
        self.print_banner()
        
        # Create necessary directories
        self.output_folder.mkdir(parents=True, exist_ok=True)
        
        # Start auto-save thread
        save_thread = threading.Thread(target=self._auto_save_state)
        save_thread.daemon = True
        save_thread.start()
        
        start_time = time.time()
        
        try:
            # Process repositories with controlled parallelism
            max_workers = min(len(WALLPAPER_REPOS), os.cpu_count() or 2)
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = [
                    executor.submit(self.process_repository, repo_url)
                    for repo_url in WALLPAPER_REPOS
                ]
                
                with tqdm(
                    total=len(WALLPAPER_REPOS),
                    desc="Processing repositories",
                    bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt}',
                    ncols=70
                ) as pbar:
                    for future in as_completed(futures):
                        if self.stop_event.is_set():
                            break
                        count, status = future.result()
                        self.total_wallpapers += count
                        print(f"\n{status}")
                        pbar.update(1)

            # Retry any failed downloads
            if self.failed_downloads and not self.stop_event.is_set():
                self._retry_failed_downloads()
            
        except Exception as e:
            self.logger.error(f"Fatal error during execution: {e}")
            raise
        finally:
            # Save final state and clean up
            self.download_state.save_state(force=True)
            self._cleanup()

        # Display final summary
        self._display_final_summary(start_time)

    def _auto_save_state(self):
        """Periodically save download state with error handling."""
        while not self.stop_event.is_set():
            try:
                time.sleep(PROGRESS_SAVE_INTERVAL)
                self.download_state.save_state()
            except Exception as e:
                self.logger.error(f"Error in auto-save: {e}")

    def _retry_failed_downloads(self):
        """Retry failed downloads with improved error handling and progress tracking."""
        if not self.failed_downloads:
            return

        print(f"\nRetrying {len(self.failed_downloads)} failed downloads...")
        
        retry_successful = 0
        remaining_failures = []
        
        with tqdm(total=len(self.failed_downloads), 
                 desc="Retrying failed downloads") as pbar:
            for source, destination in self.failed_downloads:
                try:
                    if self.stop_event.is_set():
                        break

                    source_path = Path(source)
                    if not source_path.exists():
                        self.logger.error(f"Source file no longer exists: {source}")
                        remaining_failures.append((source, destination))
                        continue

                    # Validate source file again
                    is_valid, file_hash = ImageProcessor.validate_image(source_path)
                    if not is_valid:
                        self.logger.error(f"Source file invalid: {source}")
                        remaining_failures.append((source, destination))
                        continue

                    # Attempt to copy with verification
                    shutil.copy2(source_path, destination)
                    if self._verify_file_integrity(destination, file_hash):
                        retry_successful += 1
                        self.processed_hashes[file_hash] = destination
                        self.download_state.downloaded_files.add(str(destination))
                    else:
                        if destination.exists():
                            destination.unlink()
                        remaining_failures.append((source, destination))

                except Exception as e:
                    self.logger.error(f"Retry failed for {source}: {str(e)}")
                    remaining_failures.append((source, destination))
                finally:
                    pbar.update(1)

        self.failed_downloads = remaining_failures
        
        if retry_successful:
            print(f"\nSuccessfully retried {retry_successful} downloads")
        if remaining_failures:
            print(f"\nWarning: {len(remaining_failures)} downloads still failed")

    def _verify_file_integrity(self, filepath: Path, original_hash: str) -> bool:
        """Verify file integrity with improved error handling."""
        try:
            _, new_hash = ImageProcessor.validate_image(filepath, hash_only=True)
            return new_hash == original_hash
        except Exception as e:
            self.logger.error(f"Integrity check failed for {filepath}: {e}")
            return False

    def _display_final_summary(self, start_time: float):
        """Display comprehensive summary with improved statistics."""
        elapsed_time = time.time() - start_time
        hours, remainder = divmod(int(elapsed_time), 3600)
        minutes, seconds = divmod(remainder, 60)
        
        print("\n" + "="*50)
        print("ğŸ“Š WallPimp Download Summary")
        print("="*50)
        print(f"ğŸ“ Total wallpapers downloaded: {self.total_wallpapers}")
        print(f"ğŸ’¾ Output directory: {self.output_folder}")
        print(f"â±ï¸  Time elapsed: {hours}h {minutes}m {seconds}s")
        print(f"âœ… Successfully processed repositories: {self.successful_repos}/{len(WALLPAPER_REPOS)}")
        
        try:
            total_size = sum(f.stat().st_size for f in self.output_folder.glob('**/*') 
                           if f.is_file())
            gb_size = total_size / (1024**3)
            print(f"ğŸ’½ Total data downloaded: {gb_size:.2f} GB")
        except Exception as e:
            self.logger.error(f"Error calculating total size: {e}")
        
        if self.failed_downloads:
            print(f"âš ï¸  Failed downloads: {len(self.failed_downloads)}")
            print("\nFailed files have been logged to wallpimp.log")

    def _sanitize_filename(self, filename: str) -> str:
        """Sanitize filename with improved character handling and length limits."""
        # Remove or replace invalid characters
        invalid_chars = r'[<>:"/\\|?*\x00-\x1f]'
        sanitized = re.sub(invalid_chars, '_', filename)
        
        # Remove leading/trailing spaces and dots
        sanitized = sanitized.strip('. ')
        
        # Ensure filename isn't too long (accounting for path length limits)
        max_length = 255 - len(str(self.output_folder)) - 1
        if len(sanitized) > max_length:
            name, ext = os.path.splitext(sanitized)
            sanitized = name[:max_length-len(ext)] + ext
            
        return sanitized

    def print_banner(self):
        """Display the WallPimp banner with version and feature information."""
        banner = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                 WallPimp v2.4                    â•‘
â•‘        Developed by ã‚½ãƒ­ãƒƒã‚¯ã‚¹ (oxborn3)           â•‘
â•‘        https://github.com/0xb0rn3                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ” Features:
â€¢ Optimized for large repositories
â€¢ Precise file verification and duplicate detection
â€¢ Download resume capability
â€¢ Detailed progress tracking
â€¢ Comprehensive error handling

ğŸ“‚ Output Directory: {self.output_folder}
"""
        print(banner)

def check_git_installation():
    """Verify Git installation with detailed feedback."""
    try:
        result = subprocess.run(
            ['git', '--version'], 
            check=True, 
            capture_output=True, 
            text=True
        )
        return True
    except subprocess.SubprocessError:
        print("Error: Git is not installed or not in PATH")
        print("Please install Git from: https://git-scm.com/downloads")
        return False
    except Exception as e:
        print(f"Error checking Git installation: {e}")
        return False

def main():
    """Enhanced entry point with comprehensive error handling."""
    try:
        # Check Git installation first
        if not check_git_installation():
            sys.exit(1)
            
        # Initialize and run WallPimp
        wallpimp = WallPimp()
        wallpimp.run()
        
    except KeyboardInterrupt:
        print("\n\nOperation cancelled by user. Cleaning up...")
        sys.exit(1)
    except Exception as e:
        print(f"\nFatal error: {str(e)}")
        logging.error(f"Fatal error: {str(e)}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()
