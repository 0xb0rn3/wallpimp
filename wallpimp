#!/usr/bin/env python3
"""
WallPimp v2.4 - Enhanced Cross-Platform Automated Wallpaper Collection Tool
Optimized for large repositories with precise file handling and verification.
Features improved duplicate detection, download resumption, and interactive file management.
Developed by ã‚½ãƒ­ãƒƒã‚¯ã‚¹ (oxborn3)
GitHub: https://github.com/0xb0rn3
"""
import os
import sys
import shutil
import subprocess
import platform
import requests
from pathlib import Path
import hashlib
import time
import logging
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Set, Dict, Tuple, Optional
from tqdm import tqdm
import re
from datetime import datetime
import signal
import threading
import tempfile

# Enhanced dependency handling for PIL/Pillow
try:
    from PIL import Image
except ImportError:
    print("Pillow not found. Attempting automatic installation...")
    try:
        subprocess.check_call([sys.executable, "-m", "pip", "install", "--user", "Pillow"])
        from PIL import Image
    except Exception as e:
        print(f"Error installing Pillow: {e}")
        print("\nPlease install Pillow manually:")
        print("pip install Pillow")
        sys.exit(1)

# Configuration constants
WALLPAPER_REPOS = [
    "https://github.com/dharmx/walls",
    "https://github.com/FrenzyExists/wallpapers",
    "https://github.com/Dreamer-Paul/Anime-Wallpaper",
    "https://github.com/michaelScopic/Wallpapers",
    "https://github.com/ryan4yin/wallpapers",
    "https://github.com/HENTAI-CODER/Anime-Wallpaper",
    "https://github.com/port19x/Wallpapers",
    "https://github.com/k1ng440/Wallpapers",
    "https://github.com/vimfn/walls",
    "https://github.com/expandpi/wallpapers"
]

IMAGE_FORMATS = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp', '.tiff'}
MAX_IMAGE_SIZE = 1024 * 1024 * 1024  # 1GB maximum file size
MIN_IMAGE_SIZE = 1 * 1024            # 1KB minimum file size
MIN_RESOLUTION = (1280, 720)         # Minimum resolution (HD)
MAX_RETRIES = 5                      # Maximum number of retry attempts
CLONE_TIMEOUT = 3600                 # Repository clone timeout (1 hour)
DOWNLOAD_CHUNK_SIZE = 8192           # Download chunk size for large files
PROGRESS_SAVE_INTERVAL = 60          # Save progress every 60 seconds

class ImageProcessor:
    """Handles image validation, processing, and hash generation.
    
    This class provides methods to verify image files meet size and resolution 
    requirements, calculate file hashes for deduplication, and validate image 
    integrity. It uses the PIL library for image processing and hashlib for
    generating secure hashes.
    """
    
    @staticmethod
    def validate_image(filepath: Path, hash_only: bool = False) -> Tuple[bool, Optional[str]]:
        """Validate image file and generate its hash.
        
        Args:
            filepath: Path to the image file
            hash_only: If True, skip resolution/size checks and only calculate hash
            
        Returns:
            Tuple of (is_valid, file_hash). If hash_only is True, is_valid will
            always be True unless hash generation fails.
        """
        try:
            # Check if file exists and is readable
            if not filepath.is_file():
                return False, None
                
            # Get file size
            file_size = filepath.stat().st_size
            if not hash_only:
                if file_size > MAX_IMAGE_SIZE:
                    logging.debug(f"File too large: {filepath}")
                    return False, None
                if file_size < MIN_IMAGE_SIZE:
                    logging.debug(f"File too small: {filepath}")
                    return False, None
            
            # Calculate file hash first for efficiency
            file_hash = ImageProcessor._calculate_file_hash(filepath)
            if not file_hash:
                return False, None
                
            if hash_only:
                return True, file_hash
            
            # Validate image format and dimensions
            try:
                with Image.open(filepath) as img:
                    # Verify it's a valid image format
                    if not ImageProcessor._is_valid_format(img):
                        logging.debug(f"Invalid format: {filepath}")
                        return False, None
                    
                    # Check resolution
                    width, height = img.size
                    if width < MIN_RESOLUTION[0] or height < MIN_RESOLUTION[1]:
                        logging.debug(f"Resolution too low: {filepath}")
                        return False, None
                    
                    return True, file_hash
                    
            except (OSError, Image.UnidentifiedImageError) as e:
                logging.debug(f"Error opening image {filepath}: {e}")
                return False, None
                
        except Exception as e:
            logging.error(f"Error validating {filepath}: {e}")
            return False, None
    
    @staticmethod
    def _calculate_file_hash(filepath: Path) -> Optional[str]:
        """Calculate SHA-256 hash of file contents.
        
        Uses buffered reading to handle large files efficiently.
        """
        try:
            sha256_hash = hashlib.sha256()
            with open(filepath, "rb") as f:
                # Read file in chunks to handle large files
                for chunk in iter(lambda: f.read(DOWNLOAD_CHUNK_SIZE), b""):
                    sha256_hash.update(chunk)
            return sha256_hash.hexdigest()
        except Exception as e:
            logging.error(f"Error calculating hash for {filepath}: {e}")
            return None
    
    @staticmethod
    def _is_valid_format(img: Image.Image) -> bool:
        """Check if image format is supported."""
        return img.format and f'.{img.format.lower()}' in IMAGE_FORMATS

class WallPimpError(Exception):
    """Custom exception class for WallPimp-specific errors."""
    pass

class DependencyManager:
    """Handles dependency checking and installation."""
    
    @staticmethod
    def check_environment() -> None:
        """Verify Python version and platform compatibility."""
        if sys.version_info < (3, 6):
            raise WallPimpError("Python 3.6 or higher is required")
            
        # Check for necessary system libraries based on platform
        system = platform.system().lower()
        check_methods = {
            'linux': DependencyManager._check_linux_dependencies,
            'darwin': DependencyManager._check_macos_dependencies,
            'windows': DependencyManager._check_windows_dependencies
        }
        
        if system in check_methods:
            check_methods[system]()
    
    @staticmethod
    def _check_linux_dependencies() -> None:
        """Check for required system libraries on Linux."""
        try:
            libraries = ['libjpeg', 'zlib1g', 'libpng']
            missing = []
            
            for lib in libraries:
                result = subprocess.run(['ldconfig', '-p'], 
                                     stdout=subprocess.PIPE, 
                                     stderr=subprocess.PIPE,
                                     text=True)
                if lib not in result.stdout:
                    missing.append(lib)
            
            if missing:
                print(f"Missing system libraries: {', '.join(missing)}")
                print("Please install them using your package manager:")
                print("sudo apt-get install " + " ".join(missing))
        except Exception as e:
            logging.warning(f"Could not check system libraries: {e}")
    
    @staticmethod
    def _check_macos_dependencies() -> None:
        """Check for required system libraries on macOS."""
        try:
            result = subprocess.run(['which', 'brew'], 
                                 stdout=subprocess.PIPE, 
                                 stderr=subprocess.PIPE)
            if result.returncode != 0:
                print("Homebrew not found. Some dependencies may be missing.")
                print("Visit https://brew.sh for installation instructions")
        except Exception as e:
            logging.warning(f"Could not check system dependencies: {e}")
    
    @staticmethod
    def _check_windows_dependencies() -> None:
        """Check for required components on Windows."""
        try:
            import winreg
            key_path = r"SOFTWARE\Microsoft\VisualStudio\14.0\VC\Runtimes"
            winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, key_path)
        except Exception:
            print("Warning: Visual C++ Redistributable might be missing")
            print("Visit https://aka.ms/vs/16/release/vc_redist.x64.exe")
class DownloadState:
    """Manages download state persistence and recovery for the WallPimp tool."""
    
    def __init__(self, state_file: Path):
        """Initialize download state tracking.
        
        Args:
            state_file: Path to the state JSON file
        """
        self.state_file = state_file
        self.processed_repos = set()
        self.downloaded_files = set()
        self.last_save = time.time()
        
        # Load existing state if available
        self._load_state()
    
    def _load_state(self) -> None:
        """Load previous download state from file if it exists."""
        try:
            if self.state_file.exists():
                with open(self.state_file, 'r') as f:
                    state = json.load(f)
                    self.processed_repos = set(state.get('processed_repos', []))
                    self.downloaded_files = set(state.get('downloaded_files', []))
                logging.info(f"Loaded state: {len(self.processed_repos)} repos, "
                           f"{len(self.downloaded_files)} files")
        except Exception as e:
            logging.error(f"Error loading state file: {e}")
            # Create a backup of the corrupted state file
            if self.state_file.exists():
                backup = self.state_file.with_suffix('.json.bak')
                shutil.copy2(self.state_file, backup)
                logging.info(f"Created backup of corrupted state file: {backup}")
    
    def save_state(self, force: bool = False) -> None:
        """Save current download state to file.
        
        Args:
            force: If True, save regardless of time since last save
        """
        current_time = time.time()
        # Only save if forced or enough time has passed since last save
        if not force and (current_time - self.last_save) < PROGRESS_SAVE_INTERVAL:
            return
            
        try:
            # Create temporary file for atomic write
            temp_file = self.state_file.with_suffix('.tmp')
            state = {
                'processed_repos': list(self.processed_repos),
                'downloaded_files': list(self.downloaded_files),
                'last_updated': datetime.now().isoformat()
            }
            
            with open(temp_file, 'w') as f:
                json.dump(state, f, indent=2)
            
            # Atomic replace of state file
            if platform.system().lower() == 'windows':
                # Windows needs special handling for atomic file replacement
                if self.state_file.exists():
                    self.state_file.unlink()
                temp_file.rename(self.state_file)
            else:
                # POSIX systems support atomic rename
                temp_file.replace(self.state_file)
                
            self.last_save = current_time
            logging.debug("State saved successfully")
            
        except Exception as e:
            logging.error(f"Error saving state: {e}")
            if temp_file.exists():
                temp_file.unlink()
    
    def clear_state(self) -> None:
        """Clear all download state data."""
        self.processed_repos.clear()
        self.downloaded_files.clear()
        if self.state_file.exists():
            self.state_file.unlink()
        logging.info("Download state cleared")
class WallPimp:
    """Enhanced WallPimp wallpaper collection tool."""
    
    def __init__(self):
        # Initialize DependencyManager first
        DependencyManager.check_environment()
        
        self.output_folder = self._get_default_output_folder()
        # Create output folder and its parent directories
        self.output_folder.mkdir(parents=True, exist_ok=True)
        
        # Create log directory if it doesn't exist
        log_dir = self.output_folder
        log_dir.mkdir(parents=True, exist_ok=True)
        
        self.temp_dir = Path(tempfile.mkdtemp(prefix="wallpimp_"))
        self.state_file = self.output_folder / '.wallpimp_state.json'
        
        # Set up logging before initializing other components
        self._setup_logging()
        
        self.download_state = DownloadState(self.state_file)
        self.processed_hashes = {}
        self.total_wallpapers = 0
        self.successful_repos = 0
        self.failed_downloads = []
        self.stop_event = threading.Event()
        
        # Register signal handlers
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)

    def _signal_handler(self, signum, frame):
    """Handle system signals gracefully with proper cleanup.
    
    Args:
        signum: Signal number received
        frame: Current stack frame
    """
    signal_name = signal.Signals(signum).name
    self.logger.info(f"\nReceived signal {signal_name}")
    print(f"\nReceived signal {signal_name}. Cleaning up...")
    
    # Set stop event to terminate ongoing operations
    self.stop_event.set()
    
    # Save current state
    try:
        self.download_state.save_state(force=True)
        print("Progress saved successfully")
    except Exception as e:
        self.logger.error(f"Error saving state during shutdown: {e}")
    
    # Perform cleanup
    try:
        self._cleanup()
        print("Cleanup completed")
    except Exception as e:
        self.logger.error(f"Error during cleanup: {e}")
    
    # Exit with non-zero status for interruption
    sys.exit(1)
    def _setup_logging(self):
        """Configure rotating log handler with improved formatting and directory creation."""
        log_file = self.output_folder / 'wallpimp.log'
        
        # Ensure the parent directory exists
        log_file.parent.mkdir(parents=True, exist_ok=True)
        
        # Configure logging with both file and console output
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger('WallPimp')

    def _cleanup(self):
        """Clean up temporary files and directories."""
        try:
            if self.temp_dir.exists():
                shutil.rmtree(self.temp_dir, ignore_errors=True)
        except Exception as e:
            logging.error(f"Error during cleanup: {e}")

    def _get_default_output_folder(self) -> Path:
        """Get the default output folder with extended platform support."""
        system = platform.system().lower()
        if system == 'windows':
            base_dir = os.environ.get('USERPROFILE')
        elif system == 'darwin':
            base_dir = os.path.expanduser('~/Pictures')
        else:  # Linux and others
            base_dir = os.environ.get('XDG_PICTURES_DIR', 
                                    os.path.expanduser('~/Pictures'))
        
        return Path(base_dir) / 'WallPimp'

    def process_repository(self, repo_url: str) -> Tuple[int, str]:
        """Process repository with enhanced error handling and verification."""
        if repo_url in self.download_state.processed_repos:
            return 0, f"Skipping already processed repository: {repo_url}"

        repo_name = repo_url.split('/')[-1].replace('.git', '')
        repo_path = self.temp_dir / repo_name
        wallpapers_count = 0
        status_message = ""
        
        try:
            if not self._clone_repository(repo_url, repo_path):
                return 0, f"âš ï¸  Failed to clone {repo_name}"

            # Find all potential image files
            image_files = []
            for ext in IMAGE_FORMATS:
                image_files.extend(repo_path.glob(f"**/*{ext}"))
                image_files.extend(repo_path.glob(f"**/*{ext.upper()}"))

            # Process images with detailed progress
            with tqdm(total=len(image_files), 
                     desc=f"Processing {repo_name}", 
                     leave=False) as pbar:
                for image_file in image_files:
                    if self.stop_event.is_set():
                        break

                    try:
                        # Validate and get hash
                        is_valid, file_hash = ImageProcessor.validate_image(image_file)
                        if not is_valid or not file_hash:
                            pbar.update(1)
                            continue

                        # Generate unique filename
                        new_name = self._sanitize_filename(
                            f"{repo_name}_{image_file.name}")
                        destination = self.output_folder / new_name

                        # Handle duplicates
                        if file_hash in self.processed_hashes:
                            pbar.update(1)
                            continue

                        # Copy file with verification
                        shutil.copy2(image_file, destination)
                        
                        # Verify copy integrity
                        if not self._verify_file_integrity(destination, file_hash):
                            self.logger.error(
                                f"Integrity check failed for {destination}")
                            self.failed_downloads.append((str(image_file), 
                                                       destination))
                            if destination.exists():
                                destination.unlink()
                            continue

                        # Update tracking
                        self.processed_hashes[file_hash] = destination
                        self.download_state.downloaded_files.add(str(destination))
                        wallpapers_count += 1
                        
                    except Exception as e:
                        self.logger.error(f"Error processing {image_file}: {str(e)}")
                        self.failed_downloads.append((str(image_file), destination))
                    finally:
                        pbar.update(1)

            self.successful_repos += 1
            self.download_state.processed_repos.add(repo_url)
            status_message = f"âœ“ Downloaded {wallpapers_count} wallpapers from {repo_name}"
            
        except Exception as e:
            self.logger.error(f"Error processing repository {repo_name}: {str(e)}")
            status_message = f"âš ï¸  Error processing {repo_name}: {str(e)}"
        finally:
            # Clean up repository directory
            if repo_path.exists():
                shutil.rmtree(repo_path, ignore_errors=True)
                
        return wallpapers_count, status_message

    def _clone_repository(self, repo_url: str, repo_path: Path) -> bool:
        """Clone repository with improved error handling and progress tracking."""
        for attempt in range(MAX_RETRIES):
            try:
                if attempt > 0:
                    wait_time = min(2 ** attempt, 60)
                    self.logger.info(
                        f"Retry attempt {attempt + 1} for {repo_url}, "
                        f"waiting {wait_time}s")
                    time.sleep(wait_time)

                print(f"\nCloning {repo_url}...")
                
                # Use partial clone for large repositories with depth limit
                cmd = [
                    'git', 'clone',
                    '--filter=blob:limit=1g',  # Filter large files
                    '--depth=1',  # Shallow clone for faster download
                    '--single-branch',
                    '--progress',
                    repo_url,
                    str(repo_path)
                ]
                
                process = subprocess.Popen(
                    cmd,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    universal_newlines=True
                )
                
                # Monitor clone progress with timeout
                start_time = time.time()
                while True:
                    if process.stderr is None:
                        break
                        
                    if time.time() - start_time > CLONE_TIMEOUT:
                        process.terminate()
                        raise subprocess.TimeoutExpired(cmd, CLONE_TIMEOUT)
                        
                    output = process.stderr.readline()
                    if output == '' and process.poll() is not None:
                        break
                    if output:
                        if 'Receiving objects:' in output:
                            print(f"\r{output.strip()}", end='')
                
                if process.wait() == 0:
                    print("\nClone completed successfully")
                    return True
                    
            except subprocess.TimeoutExpired:
                self.logger.error(f"Timeout while cloning {repo_url}")
                if repo_path.exists():
                    shutil.rmtree(repo_path, ignore_errors=True)
            except subprocess.SubprocessError as e:
                self.logger.error(f"Error cloning {repo_url}: {str(e)}")
                if repo_path.exists():
                    shutil.rmtree(repo_path, ignore_errors=True)
            
        return False

    def run(self):
        """Main execution method with improved error handling and resource management."""
        self.print_banner()
        
        # Create necessary directories
        self.output_folder.mkdir(parents=True, exist_ok=True)
        
        # Start auto-save thread
        save_thread = threading.Thread(target=self._auto_save_state)
        save_thread.daemon = True
        save_thread.start()
        
        start_time = time.time()
        
        try:
            # Process repositories with controlled parallelism
            max_workers = min(len(WALLPAPER_REPOS), os.cpu_count() or 2)
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = [
                    executor.submit(self.process_repository, repo_url)
                    for repo_url in WALLPAPER_REPOS
                ]
                
                with tqdm(
                    total=len(WALLPAPER_REPOS),
                    desc="Processing repositories",
                    bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt}',
                    ncols=70
                ) as pbar:
                    for future in as_completed(futures):
                        if self.stop_event.is_set():
                            break
                        count, status = future.result()
                        self.total_wallpapers += count
                        print(f"\n{status}")
                        pbar.update(1)

            # Retry any failed downloads
            if self.failed_downloads and not self.stop_event.is_set():
                self._retry_failed_downloads()
            
        except Exception as e:
            self.logger.error(f"Fatal error during execution: {e}")
            raise
        finally:
            # Save final state and clean up
            self.download_state.save_state(force=True)
            self._cleanup()

        # Display final summary
        self._display_final_summary(start_time)

    def _auto_save_state(self):
        """Periodically save download state with error handling."""
        while not self.stop_event.is_set():
            try:
                time.sleep(PROGRESS_SAVE_INTERVAL)
                self.download_state.save_state()
            except Exception as e:
                self.logger.error(f"Error in auto-save: {e}")

    def _retry_failed_downloads(self):
        """Retry failed downloads with improved error handling and progress tracking."""
        if not self.failed_downloads:
            return

        print(f"\nRetrying {len(self.failed_downloads)} failed downloads...")
        
        retry_successful = 0
        remaining_failures = []
        
        with tqdm(total=len(self.failed_downloads), 
                 desc="Retrying failed downloads") as pbar:
            for source, destination in self.failed_downloads:
                try:
                    if self.stop_event.is_set():
                        break

                    source_path = Path(source)
                    if not source_path.exists():
                        self.logger.error(f"Source file no longer exists: {source}")
                        remaining_failures.append((source, destination))
                        continue

                    # Validate source file again
                    is_valid, file_hash = ImageProcessor.validate_image(source_path)
                    if not is_valid:
                        self.logger.error(f"Source file invalid: {source}")
                        remaining_failures.append((source, destination))
                        continue

                    # Attempt to copy with verification
                    shutil.copy2(source_path, destination)
                    if self._verify_file_integrity(destination, file_hash):
                        retry_successful += 1
                        self.processed_hashes[file_hash] = destination
                        self.download_state.downloaded_files.add(str(destination))
                    else:
                        if destination.exists():
                            destination.unlink()
                        remaining_failures.append((source, destination))

                except Exception as e:
                    self.logger.error(f"Retry failed for {source}: {str(e)}")
                    remaining_failures.append((source, destination))
                finally:
                    pbar.update(1)

        self.failed_downloads = remaining_failures
        
        if retry_successful:
            print(f"\nSuccessfully retried {retry_successful} downloads")
        if remaining_failures:
            print(f"\nWarning: {len(remaining_failures)} downloads still failed")

    def _verify_file_integrity(self, filepath: Path, original_hash: str) -> bool:
        """Verify file integrity with improved error handling."""
        try:
            _, new_hash = ImageProcessor.validate_image(filepath, hash_only=True)
            return new_hash == original_hash
        except Exception as e:
            self.logger.error(f"Integrity check failed for {filepath}: {e}")
            return False

    def _display_final_summary(self, start_time: float):
        """Display comprehensive summary with improved statistics."""
        elapsed_time = time.time() - start_time
        hours, remainder = divmod(int(elapsed_time), 3600)
        minutes, seconds = divmod(remainder, 60)
        
        print("\n" + "="*50)
        print("ğŸ“Š WallPimp Download Summary")
        print("="*50)
        print(f"ğŸ“ Total wallpapers downloaded: {self.total_wallpapers}")
        print(f"ğŸ’¾ Output directory: {self.output_folder}")
        print(f"â±ï¸  Time elapsed: {hours}h {minutes}m {seconds}s")
        print(f"âœ… Successfully processed repositories: {self.successful_repos}/{len(WALLPAPER_REPOS)}")
        
        try:
            total_size = sum(f.stat().st_size for f in self.output_folder.glob('**/*') 
                           if f.is_file())
            gb_size = total_size / (1024**3)
            print(f"ğŸ’½ Total data downloaded: {gb_size:.2f} GB")
        except Exception as e:
            self.logger.error(f"Error calculating total size: {e}")
        
        if self.failed_downloads:
            print(f"âš ï¸  Failed downloads: {len(self.failed_downloads)}")
            print("\nFailed files have been logged to wallpimp.log")

    def _sanitize_filename(self, filename: str) -> str:
        """Sanitize filename with improved character handling and length limits."""
        # Remove or replace invalid characters
        invalid_chars = r'[<>:"/\\|?*\x00-\x1f]'
        sanitized = re.sub(invalid_chars, '_', filename)
        
        # Remove leading/trailing spaces and dots
        sanitized = sanitized.strip('. ')
        
        # Ensure filename isn't too long (accounting for path length limits)
        max_length = 255 - len(str(self.output_folder)) - 1
        if len(sanitized) > max_length:
            name, ext = os.path.splitext(sanitized)
            sanitized = name[:max_length-len(ext)] + ext
            
        return sanitized

    def print_banner(self):
        """Display the WallPimp banner with version and feature information."""
        banner = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                 WallPimp v2.4                    â•‘
â•‘        Developed by ã‚½ãƒ­ãƒƒã‚¯ã‚¹ (oxborn3)           â•‘
â•‘        https://github.com/0xb0rn3                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ” Features:
â€¢ Optimized for large repositories
â€¢ Precise file verification and duplicate detection
â€¢ Download resume capability
â€¢ Detailed progress tracking
â€¢ Comprehensive error handling

ğŸ“‚ Output Directory: {self.output_folder}
"""
        print(banner)

def check_git_installation():
    """Verify Git installation with detailed feedback."""
    try:
        result = subprocess.run(
            ['git', '--version'], 
            check=True, 
            capture_output=True, 
            text=True
        )
        return True
    except subprocess.SubprocessError:
        print("Error: Git is not installed or not in PATH")
        print("Please install Git from: https://git-scm.com/downloads")
        return False
    except Exception as e:
        print(f"Error checking Git installation: {e}")
        return False

def main():
    """Enhanced entry point with comprehensive error handling."""
    try:
        # Check Git installation first
        if not check_git_installation():
            sys.exit(1)
            
        # Initialize and run WallPimp
        wallpimp = WallPimp()
        wallpimp.run()
        
    except KeyboardInterrupt:
        print("\n\nOperation cancelled by user. Cleaning up...")
        sys.exit(1)
    except Exception as e:
        print(f"\nFatal error: {str(e)}")
        logging.error(f"Fatal error: {str(e)}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()
